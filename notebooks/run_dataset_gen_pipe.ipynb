{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates crops ad pickle file using dataset_gen_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook crops images according to bounding box coordinates (one per sulcus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9 (default, Jan 26 2021, 15:33:00) \n",
      "[GCC 8.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the aims module\n",
    "from soma import aims\n",
    "# the brainplot package\n",
    "import colorado as cld\n",
    "\n",
    "print((sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line permits to import deep_folding even if this notebook is executed from the notebooks subfolder (and no install has been launched):\n",
    "\n",
    " /notebooks/use_transform.ipynb  \n",
    " /deep_folding/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/host/home/jc225751/Program/deep_folding/deep_folding\n"
     ]
    }
   ],
   "source": [
    "sys.path.append((os.path.abspath('../')))\n",
    "import deep_folding\n",
    "print((os.path.dirname(deep_folding.__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ALL_SUBJECTS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sulcus = 'S.T.s.ter.asc.ant._left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 'L'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assign path names and other user-specific variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source directory is where the database lies. It contains the morphologist analysis subfolder ANALYSIS/3T_morphologist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_dir = /host/home/jc225751/Program/deep_folding/data/source/unsupervised\n"
     ]
    }
   ],
   "source": [
    "src_dir = os.path.join(os.getcwd(), '../data/source/unsupervised')\n",
    "src_dir = os.path.abspath(src_dir)\n",
    "print((\"src_dir = \" + src_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target directory tgt_dir is where the files will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_dir = /host/home/jc225751/Program/deep_folding/data/target/data/linear\n"
     ]
    }
   ],
   "source": [
    "tgt_dir = os.path.join(os.getcwd(), '../data/target/data/linear')\n",
    "tgt_dir = os.path.abspath(tgt_dir)\n",
    "print((\"tgt_dir = \" + tgt_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference directory is where the equivalent reference file has been saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_dir = /host/home/jc225751/Program/deep_folding/data/reference/data/linear\n"
     ]
    }
   ],
   "source": [
    "ref_dir = os.path.join(os.getcwd(), '../data/reference/data/linear')\n",
    "ref_dir = os.path.abspath(ref_dir)\n",
    "print((\"ref_dir = \" + ref_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_dir = /host/home/jc225751/Program/deep_folding/data/reference/transform\n"
     ]
    }
   ],
   "source": [
    "transform_dir = os.path.join(os.getcwd(), '../data/reference/transform')\n",
    "transform_dir = os.path.abspath(transform_dir)\n",
    "print((\"transform_dir = \" + transform_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox_dir = /host/home/jc225751/Program/deep_folding/data/reference/bbox\n"
     ]
    }
   ],
   "source": [
    "bbox_dir = os.path.join(os.getcwd(), '../data/reference/bbox')\n",
    "bbox_dir = os.path.abspath(bbox_dir)\n",
    "print((\"bbox_dir = \" + bbox_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jc225751/Program/deep_folding/venv/lib/python3.6/site-packages/ipykernel_launcher.py', '-f', '/casa/home/.local/share/jupyter/runtime/kernel-7ebbd46e-f2cd-49fa-8ae6-f7dc166abad3.json']\n"
     ]
    }
   ],
   "source": [
    "print((sys.argv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of main program uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first use the program with no effect by using number of subjects set to 0, or by calling the help function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using external calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../deep_folding/anatomist_tools/dataset_gen_pipe.py -n 0 -t tgt_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "!rm -rf tgt_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: bounding_box.py [-h] [-s SRC_DIR [SRC_DIR ...]] [-t TGT_DIR]\r\n",
      "                       [-u SULCUS] [-i SIDE] [-m IMAGE_NORMALIZED_SPM]\r\n",
      "                       [-p PATH_TO_GRAPH] [-n NB_SUBJECTS]\r\n",
      "\r\n",
      "Computes bounding box around the named sulcus\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -s SRC_DIR [SRC_DIR ...], --src_dir SRC_DIR [SRC_DIR ...]\r\n",
      "                        Source directory where the MRI data lies. If there are\r\n",
      "                        several directories, add all directories one after the\r\n",
      "                        other. Example: -s DIR_1 DIR_2. Default is :\r\n",
      "                        /neurospin/lnao/PClean/database_learnclean/all/\r\n",
      "  -t TGT_DIR, --tgt_dir TGT_DIR\r\n",
      "                        Target directory where to store the output\r\n",
      "                        transformation files. Default is :\r\n",
      "                        /neurospin/dico/deep_folding_data/test/bbox\r\n",
      "  -u SULCUS, --sulcus SULCUS\r\n",
      "                        Sulcus name around which we determine the bounding\r\n",
      "                        box. Default is : S.T.s.ter.asc.ant._left\r\n",
      "  -i SIDE, --side SIDE  Hemisphere side. Default is : L\r\n",
      "  -m IMAGE_NORMALIZED_SPM, --image_normalized_SPM IMAGE_NORMALIZED_SPM\r\n",
      "                        Name (with path) of normalized SPM image. It is used\r\n",
      "                        to determine voxel size. Default is : /neurospin/hcp/A\r\n",
      "                        NALYSIS/3T_morphologist/100206/t1mri/default_acquisiti\r\n",
      "                        on/normalized_SPM_100206.nii\r\n",
      "  -p PATH_TO_GRAPH, --path_to_graph PATH_TO_GRAPH\r\n",
      "                        Relative path to manually labelled graph. Default is\r\n",
      "                        t1mri/t1/default_analysis/folds/3.3/base2018_manual\r\n",
      "  -n NB_SUBJECTS, --nb_subjects NB_SUBJECTS\r\n",
      "                        Number of subjects to take into account, or 'all'. 0\r\n",
      "                        subject is allowed, for debug purpose. Default is :\r\n",
      "                        all\r\n"
     ]
    }
   ],
   "source": [
    "!python ../deep_folding/anatomist_tools/bounding_box.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using the main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/host/home/jc225751/Program/deep_folding/deep_folding/anatomist_tools/dataset_gen_pipe.py\n"
     ]
    }
   ],
   "source": [
    "from deep_folding.anatomist_tools import dataset_gen_pipe\n",
    "print((dataset_gen_pipe.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"-n 0 -t \" + tgt_dir\n",
    "argv = args.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gen_pipe.main(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"--help\"\n",
    "argv = args.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dataset_gen_pipe.py [-h] [-s SRC_DIR] [-t TGT_DIR] [-r TRANSFORM_DIR]\n",
      "                           [-b BBOX_DIR] [-u SULCUS [SULCUS ...]] [-i SIDE]\n",
      "                           [-n NB_SUBJECTS] [-e INTERP]\n",
      "\n",
      "Generates cropped and pickle files\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -s SRC_DIR, --src_dir SRC_DIR\n",
      "                        Source directory where the MRI data lies. Default is :\n",
      "                        /neurospin/hcp\n",
      "  -t TGT_DIR, --tgt_dir TGT_DIR\n",
      "                        Target directory where to store the cropped and pickle\n",
      "                        files. Default is :\n",
      "                        /neurospin/dico/deep_folding_data/test\n",
      "  -r TRANSFORM_DIR, --transform_dir TRANSFORM_DIR\n",
      "                        Transform directory where transformation files from\n",
      "                        native to Talairach files have been stored. Default is\n",
      "                        : /neurospin/dico/deep_folding_data/test/transform\n",
      "  -b BBOX_DIR, --bbox_dir BBOX_DIR\n",
      "                        Bounding box directory where json files containing\n",
      "                        bounding box coordinates have been stored. Default is\n",
      "                        : /neurospin/dico/deep_folding_data/test/bbox\n",
      "  -u SULCUS [SULCUS ...], --sulcus SULCUS [SULCUS ...]\n",
      "                        Sulcus name around which we determine the bounding\n",
      "                        box. If there are several sulci, add all sulci one\n",
      "                        after the other. Example: -u sulcus_1 sulcus_2 Default\n",
      "                        is : S.T.s.ter.asc.ant._left\n",
      "  -i SIDE, --side SIDE  Hemisphere side (either L or R). Default is : L\n",
      "  -n NB_SUBJECTS, --nb_subjects NB_SUBJECTS\n",
      "                        Number of subjects to take into account, or 'all'. 0\n",
      "                        subject is allowed, for debug purpose.Default is : all\n",
      "  -e INTERP, --interp INTERP\n",
      "                        Same interpolation type as for AimsApplyTransform.\n",
      "                        Type of interpolation used for Volumes: n[earest],\n",
      "                        l[inear], q[uadratic], c[cubic], quartic, quintic,\n",
      "                        six[thorder], seven[thorder]. Modes may also be\n",
      "                        specified as order number: 0=nearest, 1=linear...\n"
     ]
    }
   ],
   "source": [
    "dataset_gen_pipe.main(argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using the API function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gen_pipe.dataset_gen_pipe(src_dir=src_dir,\n",
    "                                  tgt_dir=tgt_dir,\n",
    "                                  transform_dir=transform_dir,\n",
    "                                  bbox_dir=bbox_dir,\n",
    "                                  list_sulci=sulcus,\n",
    "                                  side=side,\n",
    "                                  number_subjects=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crops with linear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gen_pipe.dataset_gen_pipe(src_dir=src_dir,\n",
    "                                  tgt_dir=tgt_dir,\n",
    "                                  transform_dir=transform_dir,\n",
    "                                  bbox_dir=bbox_dir,\n",
    "                                  list_sulci=sulcus,\n",
    "                                  side=side,\n",
    "                                  interp=interp,\n",
    "                                  number_subjects=_ALL_SUBJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of source skeleton =  (1, 260, 311, 260)\n"
     ]
    }
   ],
   "source": [
    "# Gets source file as numpy array\n",
    "skeleton_dir = os.path.join(src_dir, \"ANALYSIS/3T_morphologist/100206/t1mri/default_acquisition/default_analysis/segmentation\")\n",
    "vol_source_file = glob.glob(skeleton_dir + '/' + side + '*.nii.gz')\n",
    "vol_source = aims.read(vol_source_file[0])\n",
    "arr_source = vol_source.arraydata()\n",
    "print(\"shape of source skeleton = \", arr_source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 11, 30, 40, 60, 80], dtype=int16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    18832738\n",
       "0      2012736\n",
       "60      163069\n",
       "30        9634\n",
       "80        5330\n",
       "40          87\n",
       "10           6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.resize(arr_source, arr_source.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the list of files of the target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in target directory:\n",
      "Ldataset.json\n",
      "Lskeleton.pkl\n",
      "dataset.json\n",
      "Lcrops\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in target directory:\")\n",
    "print(('\\n'.join(os.listdir(tgt_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in crops target directory:\n",
      "100206_normalized.nii.gz\n",
      "100206_normalized.nii.gz.minf\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in crops target directory:\")\n",
    "print(('\\n'.join(os.listdir(tgt_dir + '/' + side + 'crops'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_json_file =  /host/home/jc225751/Program/deep_folding/data/target/data/linear/Ldataset.json \n",
      "\n",
      "{\n",
      "    \"bbmax\": [\n",
      "        137,\n",
      "        153,\n",
      "        78\n",
      "    ],\n",
      "    \"bbmin\": [\n",
      "        112,\n",
      "        129,\n",
      "        33\n",
      "    ],\n",
      "    \"bbox_dir\": \"/host/home/jc225751/Program/deep_folding/data/reference/bbox\",\n",
      "    \"cropped_dir\": \"/host/home/jc225751/Program/deep_folding/data/target/data/linear/Lcrops\",\n",
      "    \"date\": \"2021-05-25 23:58:22\",\n",
      "    \"git_sha\": \"a77d3842e313cbc2d08f9c2732ef36d23a9e6a49\",\n",
      "    \"interp\": \"linear\",\n",
      "    \"is_git\": true,\n",
      "    \"list_sulci\": [\n",
      "        \"S.T.s.ter.asc.ant._left\"\n",
      "    ],\n",
      "    \"nb_subjects\": 2,\n",
      "    \"repo_working_dir\": \"/host/home/jc225751/Program/deep_folding\",\n",
      "    \"side\": \"L\",\n",
      "    \"src_dir\": \"/host/home/jc225751/Program/deep_folding/data/source/unsupervised\",\n",
      "    \"tgt_dir\": \"/host/home/jc225751/Program/deep_folding/data/target/data/linear\",\n",
      "    \"timestamp\": 1621979902.1123571,\n",
      "    \"transform_dir\": \"/host/home/jc225751/Program/deep_folding/data/reference/transform\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tgt_json_file = glob.glob(tgt_dir + '/*.json')[0]\n",
    "print(\"tgt_json_file = \", tgt_json_file, '\\n')\n",
    "with open(os.path.join(tgt_dir, tgt_json_file), 'r') as f:\n",
    "    data_tgt = json.load(f)\n",
    "    print((json.dumps(data_tgt, sort_keys=True, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained output (we read the cropped file from the target directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of target cropped image =  (1, 46, 25, 26)\n"
     ]
    }
   ],
   "source": [
    "# Gets target crop as numpy array\n",
    "cropped_target_dir = os.path.join(tgt_dir, side+'crops')\n",
    "vol_target_file = glob.glob(cropped_target_dir + '/' + '*.nii.gz')\n",
    "vol_target = aims.read(vol_target_file[0])\n",
    "arr_target = vol_target.arraydata()\n",
    "print(\"shape of target cropped image = \", arr_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 72],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 72],\n",
      "      dtype=int16), array([21572,   252,   174,   184,   146,   137,   166,   114,   119,\n",
      "         115,   107,  3337,   105,   120,   107,   105,   119,   124,\n",
      "          92,   115,    94,    95,   109,   108,    98,   107,    95,\n",
      "         121,   102,   139,   150,   131,   106,   109,    98,    95,\n",
      "          92,    69,    62,    61,    47,    47,    45,    36,    36,\n",
      "          39,    32,    37,    32,    28,    26,    27,    13,    15,\n",
      "          16,    14,    14,    10,    10,    12,     7,     2,     1,\n",
      "           1,     2]))\n"
     ]
    }
   ],
   "source": [
    "unique_target = np.unique(arr_target, return_counts=True)\n",
    "print(unique_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     21572\n",
       "11     3337\n",
       "1       252\n",
       "3       184\n",
       "2       174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.resize(arr_target, arr_target.size)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output (we read the cropped file from the reference directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of reference cropped image =  (1, 46, 25, 26)\n"
     ]
    }
   ],
   "source": [
    "cropped_ref_dir = os.path.join(ref_dir, side+'crops')\n",
    "vol_ref_file = glob.glob(cropped_ref_dir + '/' + '*.nii.gz')\n",
    "vol_ref = aims.read(vol_ref_file[0])\n",
    "arr_ref = vol_ref.arraydata()\n",
    "print(\"shape of reference cropped image = \", arr_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     21572\n",
       "11     3336\n",
       "1       252\n",
       "3       184\n",
       "2       174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.resize(arr_ref, arr_ref.size)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(arr_target, arr_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different pixels :  2\n",
      "Index of different pixels :  (array([0, 0]), array([34, 42]), array([22,  5]), array([21, 11]))\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1\n",
    "difference = (abs(arr_ref-arr_target) >= epsilon)\n",
    "number_differences = np.count_nonzero(difference)\n",
    "index_of_differences = np.where(difference)\n",
    "print(\"Number of different pixels : \", number_differences)\n",
    "print(\"Index of different pixels : \", index_of_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(44, 45), (11, 12)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(arr_target[index_of_differences], arr_ref[index_of_differences])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_arrays_almost_equal(arr1, arr2, epsilon, max_number_different_pixels):\n",
    "    \"\"\"Returns True if at most max_number_different_pixels pixels of arrays arr1 and arr2 \n",
    "    differ by more than epsilon\n",
    "    \n",
    "    \"\"\"\n",
    "    difference = (abs(arr1-arr2) >= epsilon)\n",
    "    number_different_pixels = np.count_nonzero(difference)\n",
    "    return number_different_pixels <= max_number_different_pixels, number_different_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_arrays, number_different_pixels = are_arrays_almost_equal(arr_ref, arr_target, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(equal_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crops with nearest-neighbour interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_dir = /host/home/jc225751/Program/deep_folding/data/target/data/nearest\n"
     ]
    }
   ],
   "source": [
    "tgt_dir_nearest = os.path.join(os.getcwd(), '../data/target/data/nearest')\n",
    "tgt_dir_nearest = os.path.abspath(tgt_dir_nearest)\n",
    "print((\"tgt_dir = \" + tgt_dir_nearest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = 'nearest'\n",
    "dataset_gen_pipe.dataset_gen_pipe(src_dir=src_dir,\n",
    "                                  tgt_dir=tgt_dir_nearest,\n",
    "                                  transform_dir=transform_dir,\n",
    "                                  bbox_dir=bbox_dir,\n",
    "                                  list_sulci=sulcus,\n",
    "                                  side=side,\n",
    "                                  interp=interp,\n",
    "                                  number_subjects=_ALL_SUBJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of source skeleton =  (1, 260, 311, 260)\n"
     ]
    }
   ],
   "source": [
    "# Gets source file as numpy array\n",
    "skeleton_dir = os.path.join(src_dir, \"ANALYSIS/3T_morphologist/100206/t1mri/default_acquisition/default_analysis/segmentation\")\n",
    "vol_source_file = glob.glob(skeleton_dir + '/' + side + '*.nii.gz')[0]\n",
    "vol_source = aims.read(vol_source_file)\n",
    "arr_source = vol_source.arraydata()\n",
    "print(\"shape of source skeleton = \", arr_source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 11, 30, 40, 60, 80], dtype=int16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    18832738\n",
       "0      2012736\n",
       "60      163069\n",
       "30        9634\n",
       "80        5330\n",
       "40          87\n",
       "10           6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.resize(arr_source, arr_source.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the list of files of the target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in crops target directory:\n",
      "/host/home/jc225751/Program/deep_folding/data/target/data/nearest\n",
      "100206_normalized.nii.gz\n",
      "100206_normalized.nii.gz.minf\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in crops target directory:\")\n",
    "print(tgt_dir_nearest)\n",
    "print(('\\n'.join(os.listdir(tgt_dir_nearest + '/' + side + 'crops'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_json_file =  /host/home/jc225751/Program/deep_folding/data/target/data/nearest/Ldataset.json \n",
      "\n",
      "{\n",
      "    \"bbmax\": [\n",
      "        137,\n",
      "        153,\n",
      "        78\n",
      "    ],\n",
      "    \"bbmin\": [\n",
      "        112,\n",
      "        129,\n",
      "        33\n",
      "    ],\n",
      "    \"bbox_dir\": \"/host/home/jc225751/Program/deep_folding/data/reference/bbox\",\n",
      "    \"cropped_dir\": \"/host/home/jc225751/Program/deep_folding/data/target/data/nearest/Lcrops\",\n",
      "    \"date\": \"2021-05-25 23:58:26\",\n",
      "    \"git_sha\": \"a77d3842e313cbc2d08f9c2732ef36d23a9e6a49\",\n",
      "    \"interp\": \"nearest\",\n",
      "    \"is_git\": true,\n",
      "    \"list_sulci\": [\n",
      "        \"S.T.s.ter.asc.ant._left\"\n",
      "    ],\n",
      "    \"nb_subjects\": 2,\n",
      "    \"repo_working_dir\": \"/host/home/jc225751/Program/deep_folding\",\n",
      "    \"side\": \"L\",\n",
      "    \"src_dir\": \"/host/home/jc225751/Program/deep_folding/data/source/unsupervised\",\n",
      "    \"tgt_dir\": \"/host/home/jc225751/Program/deep_folding/data/target/data/nearest\",\n",
      "    \"timestamp\": 1621979906.0698283,\n",
      "    \"transform_dir\": \"/host/home/jc225751/Program/deep_folding/data/reference/transform\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tgt_json_file = glob.glob(tgt_dir_nearest + '/*.json')[0]\n",
    "print(\"tgt_json_file = \", tgt_json_file, '\\n')\n",
    "with open(os.path.join(tgt_dir_nearest, tgt_json_file), 'r') as f:\n",
    "    data_tgt = json.load(f)\n",
    "    print((json.dumps(data_tgt, sort_keys=True, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained output (we read the cropped file from the target directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of target cropped image =  (1, 46, 25, 26)\n"
     ]
    }
   ],
   "source": [
    "# Gets target crop as numpy array\n",
    "cropped_target_dir = os.path.join(tgt_dir_nearest, side+'crops')\n",
    "vol_target_file = glob.glob(cropped_target_dir + '/' + '*.nii.gz')\n",
    "vol_target = aims.read(vol_target_file[0])\n",
    "arr_target = vol_target.arraydata()\n",
    "print(\"shape of target cropped image = \", arr_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11, 30, 60, 80], dtype=int16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope here is to compare the different numbers present on the target array and on the source array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     81.8\n",
       "11    12.3\n",
       "60     5.4\n",
       "30     0.4\n",
       "80     0.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(pd.value_counts(np.resize(arr_target, arr_target.size))/arr_target.size*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    89.6\n",
       "0      9.6\n",
       "60     0.8\n",
       "30     0.0\n",
       "80     0.0\n",
       "40     0.0\n",
       "10     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(pd.value_counts(np.resize(arr_source, arr_source.size))/arr_source.size*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# The previous magic caputres this cell output (namely Anatomist logs)\n",
    "\n",
    "# Import anatomist and set the environment to use it here\n",
    "import anatomist.api as anatomist\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%gui qt\n",
    "\n",
    "# create an Anatomist session and capture input (so it does not appear here)\n",
    "a = anatomist.Anatomist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_image(file_name):\n",
    "    \n",
    "    # load source skeleton data (the SliceableObject)\n",
    "    object_anat = a.loadObject(file_name)\n",
    "\n",
    "    # create an Axial window in anatomist\n",
    "    w = a.createWindow(\"Axial\", geometry=[1200, 350, 500, 500])\n",
    "    object_anat.addInWindows(w)\n",
    "\n",
    "    # get a snapshot from anatomist\n",
    "    %matplotlib inline\n",
    "    img = cld.anatomist_snatpshot(w)\n",
    "    plt.imshow(img)\n",
    "    return object_anat, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in crops nearest target directory:\n",
      "100206_normalized.nii.gz\n",
      "100206_normalized.nii.gz.minf\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in crops nearest target directory:\")\n",
    "print(('\\n'.join(os.listdir(tgt_dir_nearest + '/' + side + 'crops'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/host/home/jc225751/Program/deep_folding/data/target/data/nearest/Lcrops/100206_normalized.nii.gz\n"
     ]
    }
   ],
   "source": [
    "target_file_dir = tgt_dir_nearest + '/' + side + 'crops'\n",
    "target_file_nearest = glob.glob(target_file_dir + \"/*.nii.gz\")[0]\n",
    "print(target_file_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<anatomist.cpp.anatomist.SliceableObject object at 0x7f443293bca8>,\n",
       " <anatomist.cpp.weak_shared_ptr_AWindow object at 0x7f4432957ca8>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_all_image(target_file_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/host/home/jc225751/Program/deep_folding/data/target/data/linear/Lcrops/100206_normalized.nii.gz\n"
     ]
    }
   ],
   "source": [
    "target_file_dir = tgt_dir + '/' + side + 'crops'\n",
    "target_file_linear = glob.glob(target_file_dir + \"/*.nii.gz\")[0]\n",
    "print(target_file_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<anatomist.cpp.anatomist.SliceableObject object at 0x7f440c24d8b8>,\n",
       " <anatomist.cpp.weak_shared_ptr_AWindow object at 0x7f43fc1a8438>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_all_image(target_file_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<anatomist.cpp.anatomist.SliceableObject object at 0x7f43fc16df78>,\n",
       " <anatomist.cpp.weak_shared_ptr_AWindow object at 0x7f43fc0e5a68>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN4AAAD8CAYAAAAYAxqKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARrElEQVR4nO3dXYxc5X3H8e/vzK7tJhDAQC2KUeJQVxW5iINcSlUUpYkSwDcOaoXMRUERFbkAKZHaC2guSqVGSqoSJKQWCVRUiJIQ1ATFqmgbQlFzxXt4pwYHiLKOwS3vL7K9O+ffi/PM7tnxzM7szp59ZnZ/H2k9Z55zZp7HZ+c35212/ooIzGxtFbkHYLYROXhmGTh4Zhk4eGYZOHhmGTh4Zhk0FjxJl0g6IOmgpOub6sdsEqmJ63iSWsCLwBeBGeBR4IqIeH7VOzObQE1t8S4ADkbEyxFxHLgb2NtQX2YTZ6qh5z0b+HXt/gzwh/0WbrVaMT09PfBJS6AVwSkRzE1P8267jQgUEFK6BQgEkP41y2F2dpZ2u93zRdhU8AaSdA1wDcDU1BTbt28f+JjjRcHHjh3nkih5a9s2fvrOO2wq27TKYLZoMRVBW1RhrHpp9P9gtpSZmZm+85ra1TwEnFO7vz21zYuI2yJid0TsbrVaDQ3DbDw1FbxHgZ2SdkjaBOwD9jfUl9nEaWRXMyLmJF0H/CfQAu6IiOea6MtsEjV2jBcR9wH3NfX8ZpPMn1wxy8DBM8vAwTPLwMEzyyDbBfS6EjhW9HoPELDwWdLZosXxVotjJcxJzBVCtJgTzBYFZVlSSqBAEfOX0Rc/T7/pXn0uteyg+/3/H0u3r+VYR+2/UhAUERRB7dND/vjCUsYieFMRnD4719XaeWHUWjTHVFnyAsGxd99j6+wcm8oSgFLQCmphqwevpv7KWKIvCJB6vNb6LNuzjRPbl9U/qz/WofvvvayI1I3mlwnEcWBWIrSwfJ9nNcYkeGdsmuYvzj6bRS9WVYEiiqpdwVQJH7RafP/QIdpHP+RPP76DM9slUhsQis7LQl1vveWi56mmO+3qaouFNrqXLRbPj/5jXXjBqtZ/rc/5x6Xllj3WWjAXjbXWf33+orGq63FDjnVR/0IqUQTvT2/mv3/zG16cO05QVHsbTtySGvmzoOX62PR0/MFpW6leHUF16Nm9ixOUFLSi5PSPfISjHzuZ1958m5NmZxElbRVMldUv/MT/Uf056+/D/bZU/ZYtam2d0HTvjtXC1LMtao/rXnY5/S+9rhYe16+fUcdatSngeGua96aneW/zVPWISI+VOLHfjWNmZoajR4+O14ek6462Whw49ZR0r378AfUX1fFWwanHjrJ7dpY3Nm/h4ZNPYiqCVlkd402XJeXCHhClBh2r9DrWWcmyJ471xGMqOPHx3fOa6r/f45cz1l59VP8WQTrGK1Fn/sbN21DGInhFwJZ2O93r/8IrCDaVwawKSmBTWbKp3aaIoBUtpsqowlbfuxrwnMsPXt1yXsxLhXKYZZfqfy3GmqbTbmz/v/9Q1631MhbBY9FpkFjUXp8uonO2kvm/vyuC9C4biHJ+p6g6Sul+l+43PWh+9/RSjx90f6XLLtX/cpYdsf/oBG7x4+Z/g87bUMYieCExp8GXFGeLFu1CtOZKigjahZiloCjFbCGgIKTqOK/sc1bTVlXnfIuoLif0PGy2E4xF8BTBVLQHLhdlMFUGbRWUEq0ymCqrEFIWTKXreNUph5Le1/EW9dynvecol7HssI8dtPu4Wv0vx+D+Vf/cRbpeuugRDt9AYxG8ENWF7wHKFDhFOf91D6UEIdoqKBTzwSOKrlPa/Z5/Oa+QUV5Ny+l/NcY6iqX671y26bRUm7z5+2vx3rAOjEXwFk46L32Gr3MkV90NIl2H6ly0ja5HLu5hmJMQw55hXGrZXseV/c4OjnLCZKVj7Tc9ZP/Vu1q6Xh9do6+v9d6/CauMRfA6J8sGHehXp6xr77XpZEt10kXpitZC/NTzKu6gEx29XjyDxla/P+gtf9BJkGGXXc4JnHrbqP2ndRSxEMv6KnPOhjIewev6qFE/kXYjF96n0+NSGDvHGqJz8m2lr4gmXj3rrf9ByziBS/FfJ5hl4OCZZeDgmWXg4Jll4OCZZeDgmWXg4Jll4OCZZTDSBXRJrwLvAW1gLiJ2S9oK/BD4BPAqcHlEvDXaMM3Wl9XY4v1JROyKiN3p/vXAAxGxE3gg3TezmiZ2NfcCd6bpO4EvN9CH2UQbNXgB/FTS46nQJMC2iDicpl8DtvV6oKRrJD0m6bF2e/Df4pmtJ6N+SPqiiDgk6beB+yX9T31mRITU+y+0IuI24DaALVu2+K+4bEMZaYsXEYfS7RHgXuAC4HVJZwGk2yOjDtJsvVlx8CR9VNLJnWngS8CzVJVfr0qLXQX8ZNRBmq03o+xqbgPuVfV3dFPA9yPiPyQ9Ctwj6WrgV8Dlow/TbH1ZcfAi4mXg0z3a3wC+MMqgzNY7f3LFLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLAMHzywDB88sg4HBk3SHpCOSnq21bZV0v6SX0u1pqV2SbpF0UNLTks5vcvBmk2qYLd6/AJd0tfUrPnkpsDP9XAPcujrDNFtfBgYvIn4OvNnV3K/45F7grqg8BJzaqRxkZgtWeozXr/jk2cCva8vNpLYTuDClbWQjn1yJiKCqDLvcx90WEbsjYner1Rp1GGYTZaXB61d88hBwTm257anNzGpWGrx+xSf3A1ems5sXAu/UdknNLBlYH0/SD4DPAWdImgH+BvgWvYtP3gfsAQ4CHwJfaWDMZhNvYPAi4oo+s04oPpmO964ddVBm650/uWKWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5bBSgtT3ijpkKQn08+e2rwbUmHKA5IubmrgZpNspYUpAW6OiF3p5z4ASecB+4BPpcf8kySXAjLrstLClP3sBe6OiGMR8QpVDYULRhif2bo0yjHedanO+R2dGugsozCl2Ua20uDdCpwL7AIOAzct9wlcEdY2shUFLyJej4h2RJTA7SzsTg5dmNIVYW0jW1HwOtVgk8uAzhnP/cA+SZsl7QB2Ao+MNkSz9WelhSk/J2kXVe3zV4GvAkTEc5LuAZ4H5oBrI8L7kWZdVlqY8p+XWP6bwDdHGZTZejeRn1yJVVvILI/JC56qmwghBAGhhVkFsbCQ2ZiauOAJaEVJQTnfovmtW1lt6EI4fDbOJi54ARwvWpQqqnuK+S0eFCgKkGNn423iggewqV1SRHv+MG5hixdAiQ/wbNxNZPDaBYSqbZoWNncEQTrsc/RsrA28nDBOWmXJbFHwC8Sx9z9guqwiVkoUlITkUys2ESYreBHMFQUHpwpas21aUcWsttGrQufNnY25iQpepFRtarerrZuq47vFW7hOg7d7Nr4mKnidSwdVpILw6UubUBMVPAUEop3ytnBEV9+3dBJt/E1U8Dq7mlNRpvv1kPm0ik2OiQpeJ1ah7qsg/qSKTZaJvI5nNukcPLMMHDyzDBw8swwcPLMMHDyzDBw8swwcPLMMHDyzDBw8swwcPLMMHDyzDIapCHuOpAclPS/pOUlfS+1bJd0v6aV0e1pql6RbUlXYpyWd3/R/wmzSDLPFmwP+MiLOAy4Erk2VX68HHoiIncAD6T7ApVTFSnYC11CV9DKzmmEqwh6OiCfS9HvAC1TFJvcCd6bF7gS+nKb3AndF5SHg1K7qQmYb3rKO8SR9AvgM8DCwLSIOp1mvAdvS9FBVYV2Y0jayoYMn6STgR8DXI+Ld+ryIWPZXWbowpW1kQwVP0jRV6L4XET9Oza93diHT7ZHUPnRVWLONapizmqKqh/dCRHynNms/cFWavgr4Sa39ynR280LgndouqZkx3Heu/DHw58Azkp5MbX8NfAu4R9LVwK+Ay9O8+4A9wEHgQ+Arqzlgs/VA1eFZXlu2bInt27fnHobZqpqZmeHo0aM9v4XLn1wxy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLwMEzy8DBM8vAwTPLYJTClDdKOiTpyfSzp/aYG1JhygOSLm7yP2A2iYb5CvdOYconJJ0MPC7p/jTv5oj4h/rCqWjlPuBTwO8AP5P0exHhWlxmySiFKfvZC9wdEcci4hWqGgoXrMZgzdaLUQpTAlyX6pzf0amBjgtTmg00SmHKW4FzgV3AYeCm5XTswpS2ka24MGVEvB4R7YgogdtZ2J10YUqzAVZcmLJTDTa5DHg2Te8H9knaLGkHsBN4ZPWGbDb5RilMeYWkXVS1z18FvgoQEc9Jugd4nuqM6LU+o2m2mAtTmjXEhSnNxoyDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWgYNnloGDZ5aBg2eWwTBf4b5F0iOSnkqFKf82te+Q9HAqQPlDSZtS++Z0/2Ca/4mG/w9mE2eYLd4x4PMR8WmqykCXSLoQ+DZVYcrfBd4Crk7LXw28ldpvTsuZWc0whSkjIt5Pd6fTTwCfB/41td8JfDlN7033SfO/kAqfmFkybJmuVipYcgS4H/gl8HZEzKVF6sUn5wtTpvnvAKev4pjNJt5QwUt18HZR1bq7APj9UTt2RVjbyJZ1VjMi3gYeBP4IOFVSp8xXvfjkfGHKNP8U4I0ez+WKsLZhDXNW80xJp6bp3wK+CLxAFcA/S4tdBfwkTe9P90nz/yvGoRaY2RgZpjDlWcCdklpUQb0nIv5N0vPA3ZL+DvgFVdVY0u13JR0E3gT2NTBus4nmwpRmDXFhSrMx4+CZZeDgmWXg4Jll4OCZZeDgmWXg4Jll4OCZZeDgmWXg4Jll4OCZZeDgmWUwFh+SlvS/wAfA/2Ueyhkew7xxGMekj+HjEXFmrxljETwASY9FxG6PIf8YxmUc63kM3tU0y8DBM8tgnIJ3W+4B4DHUjcM41u0YxuYYz2wjGactntmGkT14ki6RdCDVWrh+Dft9VdIzkp6U9Fhq2yrpfkkvpdvTGuj3DklHJD1ba+vZryq3pHXztKTzGxzDjZIOpfXxpKQ9tXk3pDEckHTxKo3hHEkPSno+1eT4Wmpf63XRbxzNro+IyPYDtKi+lfqTwCbgKeC8Ner7VeCMrra/B65P09cD326g388C5wPPDuoX2AP8OyDgQuDhBsdwI/BXPZY9L/1eNgM70u+rtQpjOAs4P02fDLyY+lrrddFvHI2uj9xbvAuAgxHxckQcB+6mqr2QS73uQ70exKqJiJ9Tfe3hMP3uBe6KykNUXyJ8VkNj6GcvcHdEHIuIV4CDVL+3UcdwOCKeSNPvUX1X69ms/broN45+VmV95A7efJ2FpF6DoWkB/FTS45KuSW3bIuJwmn4N2LZGY+nX71qvn+vSbtwdtd3sxseQSrl9BniYjOuiaxzQ4PrIHbycLoqI84FLgWslfbY+M6r9ijU/5ZurX+BW4FyqUmyHgZvWolNJJwE/Ar4eEe/W563luugxjkbXR+7gzddZSOo1GBoVEYfS7RHgXqrdhdc7uy/p9shajGWJftds/UTE61EVpymB21nYfWpsDJKmqV7s34uIH6fmNV8XvcbR9PrIHbxHgZ2qqstuovq69/1Ndyrpo5JO7kwDXwKeZXHdh3o9iKb163c/cGU6o3ch8E5tN2xVdR0vXUa1Pjpj2Keq0u8OYCfwyCr0J6qv+38hIr5Tm7Wm66LfOBpfH6txZmjEs0p7qM4k/RL4xhr1+UmqM1NPAc91+qWq4/cA8BLwM2BrA33/gGrXZZbq+ODqfv1SncH7x7RungF2NziG76Y+nk4vrrNqy38jjeEAcOkqjeEiqt3Ip4En08+eDOui3zgaXR/+5IpZBrl3Nc02JAfPLAMHzywDB88sAwfPLAMHzywDB88sAwfPLIP/B4++vIDJJnfcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_all_image(vol_source_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
